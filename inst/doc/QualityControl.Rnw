\documentclass{article}
\parskip 6pt
\usepackage[margin=1.25in]{geometry}
\usepackage[colorlinks=true,urlcolor=blue]{hyperref}
\usepackage[nonumberlist]{glossaries}
\usepackage{mfirstuc}

\makenoidxglossaries
\newglossaryentry{CD}{name=censored data, description=Any data containing or potentially containing censored values}
\newglossaryentry{LCD}{name=left-censored data, description=Any data containing left-censored values}
\newglossaryentry{MCD}{name=multiply-censored data, description=Any data containing right- or interval-censored values or a mixture of any types of censored values}
\newglossaryentry{UCD}{name=uncensored data, description=Any data not containing any censored values}

%\VignetteIndexEntry{Quality Control Data Analysis}
%\VignetteDepends{smwrQW}

\begin{document}
\SweaveOpts{concordance=TRUE}
\raggedright
\title{Quality Control Data Analysis}

\author{Dave Lorenz, Jeffrey Martin, and Laura Medalie}

\maketitle

\begin{abstract}
These examples demonstrate some of the functions and statistical methods for the analysis of water-quality control data that are available in the \texttt{smwrQW} package. The examples illustrate many of the concepts discussed by Mueller and others (2015).
\end{abstract}

\tableofcontents

\eject
\section{Introduction}

Most of the examples will use datasets supplied in the \textbf{smwrQW} package, but the Statistical Concepts section will use small, artificial datasets, with known properties to illustrate the use of the functions. The artificial data are class ''lcens'' rather than class ''qw,'' but the statistical methods apply to both classes.  The user should read the Working with Water-Quality Data vignette to become familiar with the management of water-quality data in the \texttt{smwrQW} package before attempting the examples in this vignette.

<<echo=TRUE>>=
# Load the smwrQW package
library(smwrQW)
# Generate normal data
set.seed(132)
Xn <- rnorm(26, mean=5)
# And left-censor it at 2 levels
Xc <- as.lcens(Xn, rep(c(4.5, 5.0), 13))
# And log-normal data
Xln <- rlnorm(26, mean=0.1, sd=0.3)
# And left censor it at 2 levels
Xlc <- as.lcens(Xln, rep(c(0.8, 1.2), 13))
# Multiply censor the data
Xmc <- censor(Xln, 0.8, 1.75)
@


\eject
\section{Statistical Concepts}

It is not possible, physically or financially, to measure all occurrences of every characteristic of interest in environmental studies. For some characteristics, any direct measurement is impossible. Thus, statistical methods are necessary to make estimates of these characteristics. Such estimates can be less than satisfying, and even the subject of disbelief or derision.

Water-quality data are complicated because the data are reported as censored values if the measured result is less than the reporting level, defined by the laboratory for each method and analyte. Censored values can be problematic for statistical analyses, particularly if some assumed value, such as zero or one-half the reporting level, is substituted for the censored result (see Helsel, 2012, for a detailed discussion). The methods in the \textbf{smwrQW} and described in this vignette provide statistically unbiased, or asymptotically unbiased, results with very little user adjustments and do not rely on simple substitution.

\subsection{Confidence Interval of the Mean}

The uncertainty of an inferential statistic often is indicated by reporting a range of values, referred to as a ''confidence interval.'' Confidence intervals are constructed to contain an unknown characteristic of the population, such as the mean, median, standard deviation, or a percentile, with a specified probability. The width of the confidence interval is the uncertainty due to estimation of a population characteristic based on sample data. Note that the estimation of a confidence interval is appropriate for random samples from a single population.

The equations for computing confidence intervals are not reproduced in this vignette. Mueller and others (2015) and Helsel (2012) present and describe the equations for the user who desires more information about the actual computation.

The \texttt{censMean.CI} function can be used to compute the confidence interval for the sample mean. There are six computational methods for the \texttt{censMean.CI} function, each designed for different distributions and censoring. The ''AMLE'' method can be used for \gls{UCD} or \gls{LCD} that can be assumed to be normally distributed. The ''MLE'' method can be used for \gls{MCD} that can be assumed to be normally distributed. The ''ROS'' method can be used for left-, multiply-, or uncensored data that are approximately normally distributed. The ''ROS'' method uses robust estimation and bootstrapping to relax the assumption of normality. The ''log AMLE'' method can be used for left-, or uncensored data that can be assumed to be log-normally distributed. The ''log MLE'' method can be used for multiply-censored data that can be assumed to be log-normally distributed. The ''log ROS'' method can be used for left-, multiply-, or uncensored data that are approximately log-normally distributed. The ''log ROS'' method uses robust estimation and bootstrapping to relax the assumption of normality.

The confidence interval for the mean of normally distributed, uncensored data can also be computed using the \texttt{t.test} function in base R as demonstrated in the code immediately following this paragraph. The code also illustrates the use of the \texttt{censMean.CI} in the \textbf{smwrQW} package. The method ''AMLE'' is used to compute the confidence interval. The adjusted maximum likelihood method, ''AMLE,'' is first-order unbiased and replicates the results from \texttt{t.test}.

<<echo=TRUE>>=
# The t.test for confidence interval of the mean
t.test(Xn, conf.level=.9)
# The adjusted maximum likelihood
censMean.CI(Xn, method="AMLE", CI=.9)
# Compare to the left-censored data
censMean.CI(Xc, method="AMLE", CI=.9)
@

Most often, water-quality data can be assumed to be from a log-normal distribution. The \texttt{method} argument must be ''log AMLE'' for an unbiased estimate of uncensored or left0censored data, ''log MLE'' for an asymptotically unbiased estimate of any \gls{CD}, or ''log ROS'' for a robust estimate for any censored data. The confidence intervals of the mean of a log-normally distributed sample are not simply back-transformed confidence intervals of the mean of the logs, see Helsel (2012) for details. The code following this paragraph demonstrates the ''log AMLE'' method for both the uncensored and leftcensored log-normal data and uses ''log MLE'' and ''log ROS'' for the mutliply censored data.

<<echo=TRUE>>=
# The AMLE, uncensored
censMean.CI(Xln, method="log AMLE", CI=.9)
# The AMLE, left censored
censMean.CI(Xlc, method="log AMLE", CI=.9)
# MLE for multiply censored
censMean.CI(Xmc, method="log MLE", CI=.9)
# and ROS
censMean.CI(Xmc, method="log ROS", CI=.9)
@

\subsection{Confidence Interval for the Median and other Percentiles}

The median and other percentiles are statistics of particular importance in QC analyses. Nonparametric confidence intervals on percentiles are calculated using the binomial probability function when applied to uncensored data (Mueller and others, 2015) and an approximation using the Kaplan-Meier method described by Helsel (2012) when the data are censored. In general, the confidence interval for the approximation is slightly smaller than that based on the binomial distribution, as demonstrated by the first part of the code following this paragraph. The \texttt{qtiles.CI} function in the \textbf{smwrStats} package computes confidence intervals for uncensored data and the \texttt{censQtiles.CI} function in the \textbf{smwrQW} package computes confidence intervals for left-censored data. The code following this paragraph demonstrates both functions. 

<<echo=TRUE>>=
# Uncensored data, by default, 90% CI for median
qtiles.CI(Xln)
censQtiles.CI(Xln)
# Compare to censored data
censQtiles.CI(Xlc)
# Compute the upper confidence interval for selected probabilities
censQtiles.CI(Xlc, probs=c(.75, .9, .95), bound="upper")
# Compare to "filled in" values
Xlc.f <- fillIn(Xlc, method="log ROS")
qtiles.CI(Xlc.f, probs=c(.95), bound="upper")
@

The maximum reported for the upper confidence level by the approximation method is the largest value in the data, which is included as an attribute of the returned value. There can be times when that is acceptable. However, if the user must know that the actual upper limit could be greater than the largest value, then the user can estimate all values using the \texttt{fillIn} function (assuming either a normal or log-normal distribution) and use the \texttt{qtiles.CI} function to determine if the upper level matches the largest value or exceeds it (returned as \texttt{NA} as in the example).

\subsection{Confidence Interval for a Proportion}

Proportions can be computed for a dataset by dividing the observations into groups, such as those less than or greater than a specified value. In water-quality analyses, proportions often are used to indicate the frequency of analyte detection or exceeding a specified threshold within the total number of observations in a sample dataset. The code following this paragraph demonstrates a simple application of determining the confidence interval of a proportion--for the largest detection limit. The code uses the \texttt{binom.test} rather than \texttt{prop.test} because it computes the exact test statistic.  Note that this example assumes no missing values; if necessary they should be removed before the analysis.

<<echo=TRUE>>=
# What is the maximum detection limit?
Xlc.max <- max(censorLevels(Xlc))
Xlc.max
# What percentage?
percentile(Xlc, 1.2)
# Compute the confidence interval
binom.test(sum(Xlc >= Xlc.max),
	length(Xlc), percentile(Xlc, 1.2, percent=FALSE))
@

\eject
\section{Analysis of Blanks} 

Blanks are used to estimate the positive bias that can be caused by extraneous contamination introduced into environmental samples during collection, processing, shipment, and laboratory analysis. Evaluation of data from field blanks depends on the inference space represented by the blanks. In general, there are two possibilities: (1) a single blank is prepared to represent potential sources of contamination that affect a specific, small set of environmental samples, or (2) multiple blanks are prepared periodically over time and space to represent potential sources of contamination that might affect a much larger set of environmental samples.

This example presents a technique for evaluating potential contamination by comparing the distribution of atrazine in environmental samples to the distribution of the 90-percent upper confidence limit for percentiles of concentration in associated field blanks (Mueller and others (2015). Out of a total of 637 data points for atrazine concentrations in field blanks associated with surface-water sampling across the United States, 630 are censored at a consistent DL of 0.004 $\mu$g/L. The lowest concentration of the 7 quantified values is 0.0035 $\mu$g/L, which is less than the DL (atrazine is an information-rich analyte for samples analyzed at the NWQL). The last 10 rows of the example dataset of atrazine field blank results are shown below.  The dataset is ordered numerically by RESULT with censored results ahead of uncensored results.

\eject
\section{Analysis of Spikes} 

Spikes are used to estimate the positive or negative bias that can affect the measured results for environmental samples because of analyte degradation or problems with the analytical methods. This bias is estimated by determining the recovery of known concentrations of the analytes in the spiked sample. Calculation of recovery for matrix spikes requires a separate environmental sample to determine the background concentration of the analyte in the unspiked matrix. Recovery in the spiked matrix samples can be compared to some criteria or to typical recovery for the analytical method based on laboratory reagent spikes.

\eject
\section{Analysis of Replicates} 

Replicates are used to measure variability, which is defined as the random error in independent measurements as the result of repeated application of the measurement process under identical conditions. Statistical evaluation of replicate variability is based on the standard deviation of measured values in the primary environmental sample and the replicate sample or samples. If only one set of a large number of replicates was collected, the standard deviation could be calculated directly; however, the general practice is to collect many sets of a small number of replicates under different conditions.

\pdfbookmark[1]{References}{bib}
\begin{thebibliography}{9}

\bibitem{H12}
Helsel, D.R. 2012, Statistics for Censored Environmental Data Using Minitab and R: New York, Wiley, 324 p.

\bibitem{DL}
Lorenz, D.L., 2016, smwrQW--an R package for managing and analyzing water-quality data, version 1.0.0: U.S. Geological Survey Open File Report 2016-XXXX.

\bibitem{TM4C4}
Mueller, D.K., Schertz, T.L., Martin, J.D., and Sandstrom, M.W., 2015, Design, analysis, and interpretation of field quality-control data for water-sampling projects: U.S. Geological Survey Techniques and Methods book 4, chap. C4, 54 p.

\end{thebibliography}

\pdfbookmark[1]{Glossary}{bib}
\printnoidxglossaries

\end{document}
